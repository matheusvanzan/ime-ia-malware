import os
import pandas as pd
from datetime import datetime

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer

from mem import check_mem


class NPL:

    def __init__(self, path_proc, max_features, ngram):
        self.path_proc = path_proc
        self.max_features = max_features
        self.ngram = ngram

    def create_corpus(self, X):

        # read docs
        corpus = []
        docs = [x[0] for x in X]
        for i, doc in enumerate(docs):
            path_doc = os.path.join(self.path_proc, f'{doc}.asm')

            print(f'{i} of {X.shape[0]} - {doc}')
            check_mem()
            with open(path_doc, encoding='utf-8') as f:
                content = f.read()
            corpus.append(content)
        return corpus

    def create_count_X(self, X):
        corpus = self.create_corpus(X)       

        # build vect
        print('CountVectorizer ...')
        start = datetime.now()
        docs = [x[0] for x in X]
        count_vect = CountVectorizer(
            max_features = self.max_features,
            ngram_range = (self.ngram, self.ngram)
        )
        count_X = count_vect.fit_transform(corpus)
        count_features = count_vect.get_feature_names_out()
        count_df = pd.DataFrame(
            data = count_X.toarray(),
            index = docs,
            columns = count_features
        )
        stop = datetime.now()
        print(stop-start)

        return count_df