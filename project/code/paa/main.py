'''
Projeto de PAA

Analisar o gasto em tempo e memoria de um processo

Classificacao de caracteres utilizando redes neurais
'''

import subprocess
import pickle
import pandas as pd

from time import sleep

def doubles(first, last):
    value = first
    while value <= last:
        value *= 2
        yield value

def main():

    epochs = [100]
    input_dims = [256] # range(32, 1024, 32) # range(0, 1000, 10)
    n_layers = [1] # range(1, 50, 5)
    values = [(x, y, z) for x in epochs for y in input_dims for z in n_layers]

    df_list = []
    features = ['epochs', 'layer_dim', 'n_layers', 'params', \
        'acc', 'time_elapsed', 'mem_max']

    for i, value in enumerate(values):
        epochs, layer_dim, n_layers = value

        # start NN process
        process_nn = subprocess.Popen([
            '/home/docky/env/bin/python', '/home/docky/code/paa/mnist.py',
            '--dest', f'/home/docky/code/paa/tmp',
            '--epochs', str(epochs),
            '--layer_dim', str(layer_dim),
            '--n_layers', str(n_layers)
        ]) 

        # start memory process
        df_mem_path = f'/home/docky/code/paa/tmp/mem_{process_nn.pid}.csv'
        process_mem = subprocess.Popen([
            '/home/docky/env/bin/python', '/home/docky/code/mem.py',
            '--dest', df_mem_path,
            '--pid', str(process_nn.pid)
        ])

        process_nn.communicate() # blocks until complete

        # get NN data
        nn_path = f'/home/docky/code/paa/tmp/nn_{process_nn.pid}.pkl'
        data = None
        while not isinstance(data, dict):
            sleep(1)
            with open(nn_path, 'rb') as f:
                data = pickle.load(f)

        # get mem data
        df_mem = None
        while not isinstance(df_mem, pd.DataFrame):
            sleep(1)
            df_mem = pd.read_csv(df_mem_path, index_col=0)

        df_mem['mem'] = df_mem['mem'].div(1024**2).round(2) # MB
        data.update({'mem_max': df_mem['mem'].max()})

        print(
            f"#{i+1}: epochs = {data['epochs']},",
            f"layer_dim = {data.get('layer_dim')},",
            f"n_layers = {data.get('n_layers')},",
            f"params = {data.get('params')},",
            f"acc = {round(100*float(data.get('acc')), 2)}%,",
            f"time_elapsed = {data.get('time_elapsed')}seg,",
            f"mem_max = {data.get('mem_max')} MB"
        )

        items = []
        for feature in features:
            items.append(data.get(feature))

        df_list.append(items)

    df = pd.DataFrame(df_list, columns=features)
    print(df)
    df.to_csv(f'/home/docky/data/paa.csv')



if __name__ == '__main__':
    main()