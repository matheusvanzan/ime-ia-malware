'''

Main code of code

'''

# import settings vars only here, inject them on other instances

import os
import settings
import datetime
import numpy as np
import pandas as pd

from argparse import ArgumentParser
from network import NNetworkManager
from processor import Processor
from npl import NPL
# from doc import DocManager


'''

Lembrar
- matriz e esparsa entao salvar num csv seria muito ruim, salvamos em pkl



Exp 1 - g1_
- ngram 1
- max file size 2
- max features 100.000
- tempo ->
- memoria ->

Exp 2 (Exp 1 with less features)
- max file size 8
- max features 10.000

Exp 
- ngram 2
- 

Exp 
- ngram 3
- 

'''


def pre():

    processor = Processor(
        docs_limit = settings.DOCS_LIMIT,
        chars_to_remove = settings.NPL_CHARS_TO_REMOVE,
        path_data_raw = settings.PATH_DATA_RAW,
        path_data_proc = settings.PATH_DATA_PROC,
        max_workers = settings.MAX_WORKERS
    )

    # pre-process files
    processor.process_all_docs()


def main(args):
   
    # g: ngram
    # mf: max features
    g_mf_list = [ 
        # (1, 10), # ok
        (1, 20),
        # (1, 100), # ok
        # (1, 1000), # ok
        # (1, 10000), # ok - error on train
        # (1, 100000), # ok
         
        # (2, 10), # ok
        (2, 20),
        # (2, 100), # ok
        # (2, 1000), # ok
        # (2, 10000), # ok
        # (2, 100000), # <-- testar 

        # (3, 10), # killed
        # (3, 100),
        # (3, 1000), # 
        # (3, 10000), # <-- testar 
        # (3, 100000), # <-- testar 
    ]

    type_ = 'tfidf' # 'count'
    path = settings.PATH_DATA_TFIDF # settings.PATH_DATA_COUNTS

    # --------------------
    # CREATE DATASET
    # --------------------

    if args.create:
        for g, mf in g_mf_list:
            network_manager = NNetworkManager(path_csv = settings.PATH_DATA_LABELS_CSV,
                max_filesize = settings.NPL_MAX_FILESIZE)
            npl = NPL(path_proc = settings.PATH_DATA_PROC, max_features = mf,
                ngram = g)

            folds = network_manager.create_folds(n_splits = 10)
            for i, X_train, X_test, Y_train, Y_test in folds:
                # i, X_train, X_test, Y_train, Y_test = list(folds)[0] # fold 1
                fold_i = i+1
                prefix = f'g{g}_ms{settings.NPL_MAX_FILESIZE}_mf{mf}_f{fold_i}'
                print(prefix)

                # CountVectorizer or TfidfVectorizer
                if network_manager.check_fold_exists(path, prefix):
                    print(f'Skip fold {type_}:{prefix}')
                else:
                    X_train = npl.create_X(X_train, type_)
                    X_test = npl.create_X(X_test, type_)
                    network_manager.save_fold(path, prefix, X_train, X_test, Y_train, Y_test)

    # --------------------
    # TRAIN AND EVALUATE
    # --------------------

    if args.train:
        network_manager = NNetworkManager(path_csv = settings.PATH_DATA_LABELS_CSV,
            max_filesize = settings.NPL_MAX_FILESIZE)

        acc_folds = []
        folds = network_manager.create_folds(n_splits = 10)
        for i, X_train, X_test, Y_train, Y_test in folds:
            # i, X_train, X_test, Y_train, Y_test = list(folds)[0] # fold 1
            fold_i = i+1

            X_train_list, X_test_list = [], []
            for g, mf in g_mf_list:
                prefix = f'g{g}_ms{settings.NPL_MAX_FILESIZE}_mf{mf}_f{fold_i}'
                # print(prefix)
        
                X_train, X_test, Y_train, Y_test = network_manager.load_fold(path, prefix)
                X_train_list.append(X_train)
                X_test_list.append(X_test)

            X_train = pd.concat(X_train_list, axis=1)
            X_test  = pd.concat(X_test_list, axis=1)

            trials = 10
            loss_list, acc_list = [], []
            for _ in range(trials):
                model = network_manager.fit(path, prefix, X_train, X_test, Y_train, Y_test)
                loss, acc = model.evaluate(X_test, Y_test, verbose=None)
                loss_list.append(loss)
                acc_list.append(acc)

            loss = sum(loss_list)/trials
            acc = sum(acc_list)/trials
            # print(acc_list)
            acc_folds.append(acc)
            print(f'fold: {fold_i}, m-acc: {round(100*acc, 2)}%, loss: {round(loss, 2)}')

        acc = sum(acc_folds)/10
        print(f'10-fold-acc: {round(100*acc, 2)}%')





if __name__ == '__main__':

    parser = ArgumentParser()
    parser.add_argument('-c', '--create', dest='create', required=False, action='store_true', help='Create dataset')
    parser.add_argument('-t', '--train', dest='train', required=False, action='store_true', help='Train the model')
    args = parser.parse_args()
    print(args)

    print(f'pid: {os.getpid()}')
    # input('press any key to continue...')

    start = datetime.datetime.now()
    # pre()
    main(args)
    stop = datetime.datetime.now()
    print(str(stop-start).split('.')[0])