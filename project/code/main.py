'''

Main code of code

'''

# import settings vars only here, inject them on other instances

import settings
import time

from tokenizer import Tokenizer
from doc import DocManager

def main():

    # declare all instances to be injected
    tokenizer = Tokenizer(
        token_max_len = settings.NPL_TOKEN_MAX_LEN
    )

    doc_manager = DocManager(
        docs_limit = settings.DOCS_LIMIT,
        path_data_raw = settings.PATH_DATA_RAW,
        path_data_tokens = settings.PATH_DATA_TOKENS,
        chars_to_remove = settings.NPL_CHARS_TO_REMOVE,
        tokenizer = tokenizer
    )

    # create docs for CountVectorizer
    # doc_manager.create_token_docs()
    
    df = doc_manager.load_token_docs(window = 2)




if __name__ == '__main__':
    start = time.time()
    main()
    stop = time.time()
    print(round((stop-start)), 'seg')