'''

Main code of code

'''

# import settings vars only here, inject them on other instances

import settings
import datetime
import numpy as np

from network import NNetworkManager
from processor import Processor
from npl import NPL
from doc import DocManager


def pre():

    processor = Processor(
        docs_limit = settings.DOCS_LIMIT,
        chars_to_remove = settings.NPL_CHARS_TO_REMOVE,
        path_data_raw = settings.PATH_DATA_RAW,
        path_data_proc = settings.PATH_DATA_PROC,
        max_workers = settings.MAX_WORKERS
    )

    # pre-process files
    processor.process_all_docs()


def main():

    # write 10-fold to file
    network_manager = NNetworkManager(
        path_csv = settings.PATH_DATA_LABELS_CSV,
        len_classes = settings.NN_LEN_CLASSES
    )

    npl = NPL(
        path_proc = settings.PATH_DATA_PROC,
        max_features = settings.NPL_MAX_FEATURES,
        ngram = 1
    )

    folds = network_manager.create_folds(n_splits = 10)
    # for i, X_train, X_test, Y_train, Y_test in folds:
    i, X_train, X_test, Y_train, Y_test = list(folds)[0] # fold 1
    fold_i = i+1

    # add features to X
    X_train = npl.create_count_X(X_train)
    X_test = npl.create_count_X(X_test)

    # save fold
    network_manager.save_fold(
        settings.PATH_DATA_COUNTS,
        fold_i, X_train, X_test, Y_train, Y_test)

    # load fold
    # fold_i = 1
    # X_train, X_test, Y_train, Y_test = network_manager.load_fold(
    #     settings.PATH_DATA_COUNTS, fold_i
    # )

    # network_manager.fit(X_train, X_test, Y_train, Y_test)





    # declare all instances to be injected
    
    # doc_manager = DocManager(
    #     docs_limit = settings.DOCS_LIMIT,
    #     path_data_raw = settings.PATH_DATA_RAW,
    #     path_data_counts = settings.PATH_DATA_COUNTS,
    #     processor = processor,
    #     max_features = settings.NPL_MAX_FEATURES,
    #     ngram = 1,
    #     max_workers = settings.MAX_WORKERS
    # )

    

    # create count docs
    # for i in range(1, settings.NPL_TOKEN_MAX_LEN+1):
    # doc_manager.set_ngram(1)
    # doc_manager.create_count_from_asm()

    # create accumulated counts
    # for i in range(1, settings.NPL_TOKEN_MAX_LEN+1):
    # doc_manager.set_ngram(1)
    # doc_manager.create_vocab_from_files()




if __name__ == '__main__':
    start = datetime.datetime.now()
    # pre()
    main()
    stop = datetime.datetime.now()
    print(str(stop-start).split('.')[0])