# 0 = all messages are logged (default behavior)
# 1 = INFO messages are not printed
# 2 = INFO and WARNING messages are not printed
# 3 = INFO, WARNING, and ERROR messages are not printed
import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

import numpy as np
import pandas as pd
import collections
import pickle

from sklearn.model_selection import train_test_split
from sklearn.model_selection import StratifiedKFold

from keras.utils import np_utils 
from keras.models import Model, Sequential
from keras import layers

from mem import check_mem


class NNetworkManager:

    def __init__(self, path_csv, max_filesize):

        self.path_csv = path_csv
        self.max_filesize = max_filesize

        # self.features = features

    def print_train_test_split(self, X_train, X_test, Y_train, Y_test):
        print('X_train', X_train.shape, type(X_train))
        print(X_train)
        print('X_test', X_test.shape, type(X_test))
        print(X_test)
        # print('Y_train', Y_train.shape, type(Y_train))
        # print(Y_train)
        # print('Y_test', Y_test.shape, type(Y_test))
        # print(Y_test)

    def create_folds(self, n_splits):
        df = pd.read_csv(self.path_csv)
        df = df[df['Size'] > 0] # != 0

        if self.max_filesize != 0:
            df = df[df['Size'] < self.max_filesize*1024**2] # < max_filesize in MB
            # df = df.groupby('Class').head(10)

        X = np.array(df['Id']).reshape(-1, 1) # matriz coluna
        y = np.array(df['Class'])

        skf = StratifiedKFold(
            n_splits = n_splits,
            shuffle = True,
            random_state = 42
        )

        for i, (train_index, test_index) in enumerate(skf.split(X, y)):
            # print("     TRAIN:", train_index, "TEST:", test_index)
            X_train, X_test = X[train_index], X[test_index]
            y_train, y_test = y[train_index], y[test_index]

            len_classes = 9 # get it from Y
            Y_train = np_utils.to_categorical(y_train, len_classes) # one-hot format
            Y_test = np_utils.to_categorical(y_test, len_classes)

            yield (i, X_train, X_test, Y_train, Y_test)

    def check_fold_exists(self, path, prefix):
        folds = ['X_train', 'X_test', 'Y_train', 'Y_test']

        return all([
            os.path.exists(f'{path}/{prefix}_{fold}.pkl') for fold in folds])

    def save_fold(self, path, prefix, X_train, X_test, Y_train, Y_test):
        # pd.DataFrame(df).to_csv(f'{path}/{prefix}_{df_name}.csv', encoding='utf-8')

        self.print_train_test_split(X_train, X_test, Y_train, Y_test)

        with open(f'{path}/{prefix}_X_train.pkl', 'wb') as f:
            pickle.dump(X_train, f)

        with open(f'{path}/{prefix}_X_test.pkl', 'wb') as f:
            pickle.dump(X_test, f)

        with open(f'{path}/{prefix}_Y_train.pkl', 'wb') as f:
            pickle.dump(Y_train, f)

        with open(f'{path}/{prefix}_Y_test.pkl', 'wb') as f:
            pickle.dump(Y_test, f)

    def load_fold(self, path, prefix):
        # df_return.append(pd.read_csv(f'{path}/{prefix}_{df_name}.csv', index_col = 0))
        
        with open(f'{path}/{prefix}_X_train.pkl', 'rb') as f:
            X_train = pickle.load(f)

        with open(f'{path}/{prefix}_X_test.pkl', 'rb') as f:
            X_test = pickle.load(f)

        with open(f'{path}/{prefix}_Y_train.pkl', 'rb') as f:
            Y_train = pickle.load(f)

        with open(f'{path}/{prefix}_Y_test.pkl', 'rb') as f:
            Y_test = pickle.load(f)

        # self.print_train_test_split(X_train, X_test, Y_train, Y_test)

        return (X_train, X_test, Y_train, Y_test)


    def fit(self, path, prefix, X_train, X_test, Y_train, Y_test):

        epochs = 20  # inject

        features_len = int(X_train.shape[1])
        classes_len = int(Y_train.shape[1])

        # print('features_len', features_len)
        # print('classes_len', classes_len)

        # define network

        model = Sequential([
            layers.Input(shape=(features_len,)),
            layers.Dense(units=1024, activation='relu'),
            layers.Dense(units=classes_len, activation='softmax'),
        ])

        # print(model.summary())

        # model.add(Dense(features_len, activation='sigmoid')) # relu: most common for hidden layers
        # model.add(Dense(int(features_len/2 + classes_len/2), activation='sigmoid'))
        # model.add(Dense(512, input_shape=(784,))) #(784,) is not a typo -- that represents a 784 length vector!
        # model.add(Activation('relu'))
        # layers.Dropout(rate=0.5, seed=42),
        # Dropout

        # compile network
        model.compile(
            loss='categorical_crossentropy', # binary_crossentropy mean_squared_error mse
            optimizer='adam', # adam sgd adadelta
            metrics=[
                'accuracy', # accuracy MeanSquaredError AUC 
            ]
        )

        # fit network
        model.fit(X_train, Y_train, 
            epochs=epochs, 
            # batch_size=10,
            verbose=None
        )

        with open(f'{path}/{prefix}_model.pkl', 'wb') as f:
            pickle.dump(model, f)

        # evaluate
        # TODO: evaluate by class
        # loss, acc = model.evaluate(X_test, Y_test, verbose=None)
        # print(f'    Accuracy: {100*acc}%, Loss {loss}')

        return model
